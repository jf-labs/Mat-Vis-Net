{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f05134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paths and metadata loading ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"san_leandro_products.csv\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"\n",
    "\n",
    "print(\"CSV:\", CSV_PATH)\n",
    "print(\"Images dir:\", IMAGES_DIR)\n",
    "\n",
    "# Load full CSV (all products)\n",
    "raw_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Filtered view: only products that have an image file\n",
    "df = raw_df[raw_df[\"image_filename\"].notna() & (raw_df[\"image_filename\"] != \"\")]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Full CSV rows:\", len(raw_df))\n",
    "print(\"Filtered rows with images:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93136c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Adjust the column name if yours is different\n",
    "IMAGE_COL = \"image_filename\"\n",
    "\n",
    "if IMAGE_COL not in df.columns:\n",
    "    raise ValueError(f\"{IMAGE_COL!r} column not found in CSV. Check your column names.\")\n",
    "\n",
    "# Keep only rows that actually have an image file\n",
    "df = df[df[IMAGE_COL].notna() & (df[IMAGE_COL] != \"\")]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Rows with images:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4640442",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c87247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_image(path: Path) -> np.ndarray:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "\n",
    "    # Normalize and flatten to 1D numpy\n",
    "    emb = outputs[0]\n",
    "    emb = emb / emb.norm(p=2)\n",
    "    return emb.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1369af",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = []\n",
    "kept_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    img_name = row[IMAGE_COL]\n",
    "    img_path = IMAGES_DIR / img_name\n",
    "\n",
    "    if not img_path.exists():\n",
    "        # Skip rows with missing files\n",
    "        continue\n",
    "\n",
    "    emb = embed_image(img_path)\n",
    "    emb_list.append(emb)\n",
    "    kept_rows.append(row)\n",
    "\n",
    "len(emb_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7874611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- paths ---\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"san_leandro_products.csv\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"\n",
    "\n",
    "# --- load metadata ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df[df[\"image_filename\"].notna() & (df[\"image_filename\"] != \"\")].reset_index(drop=True)\n",
    "print(\"rows with images:\", len(df))\n",
    "\n",
    "# ---------- STEP 1: material grouping ----------\n",
    "MATERIAL_SOURCE_COLS = [\"body\", \"material\", \"category_slug\"]\n",
    "\n",
    "def infer_material_source_col(df):\n",
    "    for col in MATERIAL_SOURCE_COLS:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "MATERIAL_COL = infer_material_source_col(df)\n",
    "print(\"Using material source column:\", MATERIAL_COL)\n",
    "\n",
    "def normalize_material(text: str) -> str:\n",
    "    t = str(text).lower()\n",
    "\n",
    "    # --- Tile families ---\n",
    "    if \"porcelain\" in t:\n",
    "        if \"wood\" in t:\n",
    "            return \"wood_look_porcelain\"\n",
    "        return \"porcelain\"\n",
    "    if \"ceramic\" in t:\n",
    "        return \"ceramic\"\n",
    "\n",
    "    # --- Wood / wood-like families ---\n",
    "    if \"laminate\" in t:\n",
    "        return \"laminate\"\n",
    "    if \"vinyl\" in t or \"lvp\" in t or \"lvt\" in t:\n",
    "        return \"vinyl\"\n",
    "    if \"engineered\" in t:\n",
    "        return \"engineered_wood\"\n",
    "    if \"solid\" in t and (\"hardwood\" in t or \"wood\" in t):\n",
    "        return \"solid_wood\"\n",
    "    if \"hardwood\" in t or \"wood\" in t:\n",
    "        return \"wood\"\n",
    "\n",
    "    return \"other\"\n",
    "\n",
    "if MATERIAL_COL is not None:\n",
    "    df[\"material_group\"] = df[MATERIAL_COL].apply(normalize_material)\n",
    "else:\n",
    "    df[\"material_group\"] = \"other\"\n",
    "\n",
    "print(df[\"material_group\"].value_counts())\n",
    "\n",
    "# ---------- CLIP model ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# first time this line runs, it may download the processor files\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- helpers ---\n",
    "def load_image(path: Path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "def embed_images(image_paths, batch_size=16):\n",
    "    all_embs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        images = [load_image(p) for p in batch_paths]\n",
    "\n",
    "        inputs = processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.get_image_features(**inputs)  # [B, D]\n",
    "\n",
    "        # normalize\n",
    "        embs = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n",
    "        all_embs.append(embs.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embs)\n",
    "\n",
    "# --- build list of image paths ---\n",
    "image_paths = [IMAGES_DIR / fname for fname in df[\"image_filename\"].tolist()]\n",
    "missing = [p for p in image_paths if not p.exists()]\n",
    "print(\"missing image files:\", len(missing))\n",
    "\n",
    "# --- actually compute embeddings ---\n",
    "image_embs = embed_images(image_paths, batch_size=16)\n",
    "print(\"image_embs shape:\", image_embs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0559a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# NearestNeighbors with cosine distance (1 - cosine similarity)\n",
    "nn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
    "nn.fit(image_embs)\n",
    "\n",
    "print(\"Index built over\", image_embs.shape[0], \"products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b33aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_by_index(query_idx, top_k=5):\n",
    "    \"\"\"\n",
    "    Return the top_k nearest neighbors for a given product index,\n",
    "    excluding the product itself, deduping by image, and enforcing\n",
    "    material-aware filtering.\n",
    "\n",
    "    - Never return the exact same SKU as the query.\n",
    "    - Never show the same image twice (even if SKU differs).\n",
    "    - If the query is any kind of wood/laminate/vinyl/etc, only return\n",
    "      the *same* material_group (so wood won't match laminate/vinyl/\n",
    "      solid/engineered and vice versa).\n",
    "    - Tile vs non-tile is also separated (porcelain/ceramic vs wood stuff).\n",
    "    \"\"\"\n",
    "    # Embedding for the query product\n",
    "    query_emb = image_embs[query_idx].reshape(1, -1)\n",
    "    query_row = df.iloc[query_idx]\n",
    "    query_sku = query_row[\"sku\"]\n",
    "    query_group = query_row.get(\"material_group\", \"other\")\n",
    "\n",
    "    # Ask for some extra neighbors to survive filtering/dedup\n",
    "    n_neighbors = min(top_k + 20, len(df))\n",
    "    distances, indices = nn.kneighbors(query_emb, n_neighbors=n_neighbors)\n",
    "    distances = distances[0]\n",
    "    indices = indices[0]\n",
    "\n",
    "    results = []\n",
    "    seen_images = set()\n",
    "\n",
    "    # Groups that we treat as wood-family, but we still\n",
    "    # don't mix them with each other unless group matches exactly.\n",
    "    wood_groups = {\"wood\", \"engineered_wood\", \"solid_wood\", \"laminate\", \"vinyl\"}\n",
    "\n",
    "    # Tile-like groups\n",
    "    tile_groups = {\"porcelain\", \"ceramic\", \"wood_look_porcelain\"}\n",
    "\n",
    "    for dist, idx in zip(distances, indices):\n",
    "        # Skip the exact same row\n",
    "        if idx == query_idx:\n",
    "            continue\n",
    "\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        # Skip same SKU as the query\n",
    "        if row[\"sku\"] == query_sku:\n",
    "            continue\n",
    "\n",
    "        img_key = row[\"image_filename\"]\n",
    "\n",
    "        # Skip duplicate images\n",
    "        if img_key in seen_images:\n",
    "            continue\n",
    "\n",
    "        candidate_group = row.get(\"material_group\", \"other\")\n",
    "\n",
    "        # ---------- MATERIAL FILTERING ----------\n",
    "\n",
    "        if query_group in wood_groups:\n",
    "            # If query is wood-like (wood, laminate, vinyl, engineeered, solid),\n",
    "            # require exact same material_group.\n",
    "            #\n",
    "            # This is where your rule kicks in:\n",
    "            # \"if it's wood, exclude laminate vs vinyl vs solid vs engineered\"\n",
    "            # because those are all separate groups.\n",
    "            if candidate_group != query_group:\n",
    "                continue\n",
    "        else:\n",
    "            # For non-wood queries, keep tile vs non-tile separated.\n",
    "            query_is_tile = query_group in tile_groups\n",
    "            candidate_is_tile = candidate_group in tile_groups\n",
    "\n",
    "            # Don't mix tile with non-tile\n",
    "            if query_is_tile != candidate_is_tile:\n",
    "                continue\n",
    "\n",
    "        # ---------- END MATERIAL FILTERING ----------\n",
    "\n",
    "        seen_images.add(img_key)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"rank\": len(results) + 1,\n",
    "                \"sku\": row[\"sku\"],\n",
    "                \"name\": row[\"name\"],\n",
    "                \"category\": row[\"category_slug\"],\n",
    "                \"material_group\": candidate_group,\n",
    "                \"distance\": float(dist),\n",
    "                \"image_path\": str(IMAGES_DIR / row[\"image_filename\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Pick a sample index (try different numbers later)\n",
    "query_idx = 0\n",
    "\n",
    "query_row = df.iloc[query_idx]\n",
    "query_img = load_image(IMAGES_DIR / query_row[\"image_filename\"])\n",
    "\n",
    "print(\"Query SKU:\", query_row[\"sku\"])\n",
    "print(\"Name:\", query_row[\"name\"])\n",
    "print(\"Category:\", query_row[\"category_slug\"])\n",
    "display(query_img)\n",
    "\n",
    "results = search_similar_by_index(query_idx, top_k=5)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f}\")\n",
    "    display(load_image(Path(r[\"image_path\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 20  # example\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "labels = kmeans.fit_predict(image_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b00d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBS_PATH = PROJECT_ROOT / \"data\" / \"image_embs.npy\"\n",
    "np.save(EMBS_PATH, image_embs)\n",
    "print(\"Saved embeddings to:\", EMBS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Build kNN index over all embeddings\n",
    "# (you can tune n_neighbors here; we still cap with top_k later)\n",
    "nn = NearestNeighbors(n_neighbors=50, metric=\"cosine\")\n",
    "nn.fit(image_embs)\n",
    "\n",
    "def search_similar_by_index(query_idx: int, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Core search: given a row index into df/image_embs, return the top_k\n",
    "    most similar products (excluding the query itself and same SKU).\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    if query_idx < 0 or query_idx >= n:\n",
    "        raise IndexError(f\"query_idx {query_idx} out of range for df with {n} rows\")\n",
    "\n",
    "    # Get query embedding\n",
    "    query_emb = image_embs[query_idx]\n",
    "\n",
    "    # Ask for top_k + 1 so we can drop the self-match\n",
    "    distances, indices = nn.kneighbors([query_emb], n_neighbors=top_k + 1)\n",
    "\n",
    "    distances = distances[0]\n",
    "    indices = indices[0]\n",
    "\n",
    "    results = []\n",
    "    query_row = df.iloc[query_idx]\n",
    "    query_sku = str(query_row[\"sku\"])\n",
    "\n",
    "    for idx, dist in zip(indices, distances):\n",
    "        # Skip the query itself (same index)\n",
    "        if idx == query_idx:\n",
    "            continue\n",
    "\n",
    "        row = df.iloc[idx]\n",
    "        # Also skip any product with the same SKU (duplicate images, variants)\n",
    "        if str(row[\"sku\"]) == query_sku:\n",
    "            continue\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"rank\": len(results) + 1,\n",
    "                \"distance\": float(dist),\n",
    "                \"sku\": str(row[\"sku\"]),\n",
    "                \"name\": row[\"name\"],\n",
    "                \"category_slug\": row.get(\"category_slug\", \"\"),\n",
    "                \"image_path\": str(IMAGES_DIR / row[\"image_filename\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f21c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_by_sku(query_sku: str) -> int:\n",
    "    \"\"\"\n",
    "    Find the dataframe index for a given SKU in the filtered df\n",
    "    (the one that has embeddings).\n",
    "\n",
    "    If it's only in raw_df, raise a clearer error.\n",
    "    \"\"\"\n",
    "    sku_str = str(query_sku).strip()\n",
    "\n",
    "    # Compare as stripped strings to avoid whitespace issues\n",
    "    mask = df[\"sku\"].astype(str).str.strip() == sku_str\n",
    "    matches = df.index[mask].tolist()\n",
    "\n",
    "    if not matches:\n",
    "        # If we kept a full copy of the CSV, check there for a better error\n",
    "        if \"raw_df\" in globals():\n",
    "            raw_mask = raw_df[\"sku\"].astype(str).str.strip() == sku_str\n",
    "            if raw_mask.any():\n",
    "                raise ValueError(\n",
    "                    f\"SKU {sku_str!r} exists in san_leandro_products.csv \"\n",
    "                    f\"but was filtered out of df (likely missing image_filename, \"\n",
    "                    f\"so there is no precomputed embedding for it).\"\n",
    "                )\n",
    "\n",
    "        # Truly not found anywhere\n",
    "        raise ValueError(f\"SKU {sku_str!r} not found in CSV/df.\")\n",
    "\n",
    "    return matches[0]\n",
    "\n",
    "\n",
    "\n",
    "def get_index_by_name(query_name: str, exact: bool = False, occurrence: int = 0) -> int:\n",
    "    \"\"\"\n",
    "    Find the dataframe index for a given product name.\n",
    "\n",
    "    - If exact=False (default), uses case-insensitive substring match.\n",
    "    - If exact=True, requires full-case-insensitive equality.\n",
    "    - If multiple matches, pick which one with `occurrence` (0 = first).\n",
    "\n",
    "    Raises ValueError if nothing matches or occurrence is out of range.\n",
    "    \"\"\"\n",
    "    names = df[\"name\"].astype(str)\n",
    "\n",
    "    if exact:\n",
    "        mask = names.str.casefold() == query_name.casefold()\n",
    "    else:\n",
    "        mask = names.str.contains(query_name, case=False, na=False)\n",
    "\n",
    "    matches = df.index[mask].tolist()\n",
    "    if not matches:\n",
    "        raise ValueError(f\"No product name matching {query_name!r} found.\")\n",
    "\n",
    "    if not (0 <= occurrence < len(matches)):\n",
    "        raise ValueError(\n",
    "            f\"Found {len(matches)} matches for {query_name!r}, \"\n",
    "            f\"but occurrence={occurrence} is out of range.\"\n",
    "        )\n",
    "\n",
    "    return matches[occurrence]\n",
    "\n",
    "\n",
    "def search_similar_by_sku(query_sku, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Wrapper around search_similar_by_index that lets you search by SKU.\n",
    "    \"\"\"\n",
    "    idx = get_index_by_sku(query_sku)\n",
    "    return search_similar_by_index(idx, top_k=top_k)\n",
    "\n",
    "\n",
    "def search_similar_by_name(\n",
    "    query_name: str,\n",
    "    top_k: int = 5,\n",
    "    exact: bool = False,\n",
    "    occurrence: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper around search_similar_by_index that lets you search by name\n",
    "    (exact or substring), picking the Nth match if there are multiple.\n",
    "    \"\"\"\n",
    "    idx = get_index_by_name(query_name, exact=exact, occurrence=occurrence)\n",
    "    return search_similar_by_index(idx, top_k=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# --- EXAMPLE: query by SKU ---\n",
    "# Put a real SKU from your CSV here:\n",
    "query_sku = \"101156321\"  # change this to whatever you want\n",
    "\n",
    "# Find the index and show the query product\n",
    "query_idx = get_index_by_sku(query_sku)\n",
    "query_row = df.iloc[query_idx]\n",
    "\n",
    "print(\"QUERY PRODUCT\")\n",
    "print(\"-------------\")\n",
    "print(\"SKU:\", query_row[\"sku\"])\n",
    "print(\"Name:\", query_row[\"name\"])\n",
    "print(\"Category:\", query_row.get(\"category_slug\", \"\"))\n",
    "\n",
    "# Show query image\n",
    "query_img_path = IMAGES_DIR / query_row[\"image_filename\"]\n",
    "try:\n",
    "    from PIL import Image\n",
    "    display(Image.open(query_img_path))\n",
    "except FileNotFoundError:\n",
    "    print(\"(Query image file not found at:\", query_img_path, \")\")\n",
    "except Exception as e:\n",
    "    print(\"(Error opening query image:\", e, \")\")\n",
    "\n",
    "# Run similarity search\n",
    "results = search_similar_by_sku(query_sku, top_k=5)\n",
    "\n",
    "print(\"\\nSIMILAR PRODUCTS\")\n",
    "print(\"----------------\")\n",
    "for r in results:\n",
    "    print(f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f}\")\n",
    "    print(\"  Name:\", r[\"name\"])\n",
    "    print(\"  Category:\", r[\"category_slug\"])\n",
    "    try:\n",
    "        img = Image.open(r[\"image_path\"])\n",
    "        display(img)\n",
    "    except FileNotFoundError:\n",
    "        print(\"  (Image file not found at:\", r['image_path'], \")\")\n",
    "    except Exception as e:\n",
    "        print(\"  (Error opening image:\", e, \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXAMPLE: query by product name (substring) ---\n",
    "\n",
    "# This can be something like \"oak\", \"montauk\", \"ledger\", etc.\n",
    "query_name = \"oak\"   # change this as needed\n",
    "\n",
    "results_by_name = search_similar_by_name(\n",
    "    query_name,\n",
    "    top_k=5,\n",
    "    exact=False,      # set True if you want exact name match\n",
    "    occurrence=0,     # if multiple matches, which one to use (0 = first)\n",
    ")\n",
    "\n",
    "print(f\"Query name substring: {query_name!r}\")\n",
    "print(\"------------------------------\")\n",
    "for r in results_by_name:\n",
    "    print(f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f}\")\n",
    "    print(\"  Name:\", r[\"name\"])\n",
    "    print(\"  Category:\", r[\"category_slug\"])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
