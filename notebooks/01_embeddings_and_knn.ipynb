{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2aee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # just for loading images\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"san_leandro_products.csv\"\n",
    "EMBS_PATH = PROJECT_ROOT / \"data\" / \"image_embs.npy\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"  # <-- folder with your JPGs\n",
    "\n",
    "print(\"CSV:\", CSV_PATH)\n",
    "print(\"Embeddings:\", EMBS_PATH)\n",
    "print(\"Images dir:\", IMAGES_DIR)\n",
    "\n",
    "# Load full CSV (all products)\n",
    "raw_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Filtered view: only products that have an image file\n",
    "IMAGE_COL = \"image_filename\"\n",
    "if IMAGE_COL not in raw_df.columns:\n",
    "    raise ValueError(f\"{IMAGE_COL!r} column not found in CSV\")\n",
    "\n",
    "df = raw_df[raw_df[IMAGE_COL].notna() & (raw_df[IMAGE_COL] != \"\")]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Full CSV rows:\", len(raw_df))\n",
    "print(\"Filtered rows with images (used for embeddings):\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# If you don't already have these installed in your venv, run:\n",
    "#   pip install \"torch\" \"transformers\"\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def build_clip_image_embs(df, images_dir, image_col=\"image_filename\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Build CLIP image embeddings for every row in df and return:\n",
    "      - image_embs: numpy array of shape (N, D)\n",
    "      - df_aligned: df restricted to rows that actually have an image file\n",
    "    \"\"\"\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    print(f\"Loading CLIP model: {model_name}\")\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embs = []\n",
    "    keep_indices = []\n",
    "\n",
    "    n = len(df)\n",
    "    print(f\"Computing embeddings for {n} products...\")\n",
    "\n",
    "    for start in range(0, n, batch_size):\n",
    "        batch = df.iloc[start : start + batch_size]\n",
    "        images = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, row in batch.iterrows():\n",
    "            fname = str(row[image_col])\n",
    "            img_path = images_dir / fname\n",
    "            if not img_path.is_file():\n",
    "                print(f\"WARNING: image file missing for index {idx}: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            images.append(img)\n",
    "            batch_indices.append(idx)\n",
    "\n",
    "        if not images:\n",
    "            continue\n",
    "\n",
    "        inputs = processor(images=images, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_image_features(**inputs)\n",
    "\n",
    "        all_embs.append(emb.cpu().numpy())\n",
    "        keep_indices.extend(batch_indices)\n",
    "\n",
    "        print(f\"  processed {min(start + batch_size, n)}/{n} rows\", end=\"\\r\")\n",
    "\n",
    "    if not all_embs:\n",
    "        raise RuntimeError(\n",
    "            \"No embeddings were built. Check that your images directory is correct.\"\n",
    "        )\n",
    "\n",
    "    image_embs = np.vstack(all_embs)\n",
    "    df_aligned = df.loc[keep_indices].reset_index(drop=True)\n",
    "\n",
    "    print()\n",
    "    print(\"Embeddings built. image_embs shape:\", image_embs.shape)\n",
    "    print(\"Aligned df length:\", len(df_aligned))\n",
    "\n",
    "    return image_embs, df_aligned\n",
    "\n",
    "\n",
    "# --- Load or rebuild embeddings so that they ALWAYS match df ---\n",
    "\n",
    "if EMBS_PATH.exists():\n",
    "    image_embs = np.load(EMBS_PATH)\n",
    "    print(\"Loaded existing embeddings:\", image_embs.shape)\n",
    "else:\n",
    "    image_embs = None\n",
    "    print(\"No existing embeddings file found at\", EMBS_PATH)\n",
    "\n",
    "if (image_embs is None) or (image_embs.shape[0] != len(df)):\n",
    "    print(\"Embeddings are missing or out of sync with CSV -> rebuilding from images.\")\n",
    "    image_embs, df = build_clip_image_embs(df, IMAGES_DIR, IMAGE_COL, batch_size=32)\n",
    "    np.save(EMBS_PATH, image_embs)\n",
    "    print(\"Saved fresh embeddings to\", EMBS_PATH)\n",
    "\n",
    "print(\"Final check -> image_embs.shape[0]:\", image_embs.shape[0], \" len(df):\", len(df))\n",
    "\n",
    "if image_embs.shape[0] != len(df):\n",
    "    raise ValueError(\n",
    "        \"After rebuild, embeddings still do not align with df. \"\n",
    "        \"This would only happen if some rows were dropped while building embeddings \"\n",
    "        \"but df was not updated. Double-check your CSV and images.\"\n",
    "    )\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=20, metric=\"cosine\")\n",
    "nn.fit(image_embs)\n",
    "\n",
    "print(\"kNN index built over\", image_embs.shape[0], \"products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f582f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- material bucketing + helpers ---\n",
    "\n",
    "def _compute_material_bucket(row) -> str:\n",
    "    \"\"\"\n",
    "    Coarse material/type bucket so we don't mix wood planks with vinyl, tile,\n",
    "    or installation trim (stair nose, etc.). Uses category_slug + name + URL.\n",
    "    \"\"\"\n",
    "    cat = str(row.get(\"category_slug\", \"\")).lower().strip()\n",
    "    base = cat.strip(\"/\").split(\"/\")[-1]  # e.g. \"engineered-hardwood-wood\"\n",
    "    name = str(row.get(\"name\", \"\")).lower()\n",
    "    url = str(row.get(\"product_url\", \"\")).lower()\n",
    "\n",
    "    # --- installation / trim first (never treated as surface) ---\n",
    "    if \"installation-materials\" in base:\n",
    "        return \"install\"\n",
    "    if any(k in name for k in [\"stair nose\", \"stairnose\", \"stair-nose\"]):\n",
    "        return \"trim\"\n",
    "    if \"moldings-wood\" in url or \"molding\" in name:\n",
    "        return \"trim\"\n",
    "\n",
    "    # --- main surface families (from category_slug) ---\n",
    "    if \"wood\" in base:\n",
    "        return \"wood\"\n",
    "    if \"laminate\" in base:\n",
    "        return \"laminate\"\n",
    "    if \"vinyl\" in base or \"nucore\" in base:\n",
    "        return \"vinyl\"\n",
    "    if \"tile\" in base:\n",
    "        return \"tile\"\n",
    "    if \"stone\" in base:\n",
    "        return \"stone\"\n",
    "    if \"decoratives\" in base:\n",
    "        return \"decoratives\"\n",
    "    if \"fixtures\" in base or \"bathroom-accessories\" in base:\n",
    "        return \"fixtures\"\n",
    "\n",
    "    return \"other\"\n",
    "\n",
    "\n",
    "# compute once for the DataFrame used by embeddings\n",
    "if \"material_bucket\" not in df.columns:\n",
    "    df[\"material_bucket\"] = df.apply(_compute_material_bucket, axis=1)\n",
    "\n",
    "\n",
    "def get_index_by_sku(query_sku: str) -> int:\n",
    "    \"\"\"\n",
    "    Return the row index in df corresponding to the given SKU.\n",
    "    Only SKUs present in the filtered df (with embeddings) are valid.\n",
    "    \"\"\"\n",
    "    sku_str = str(query_sku).strip()\n",
    "    matches = df.index[df[\"sku\"].astype(str).str.strip() == sku_str].tolist()\n",
    "    if not matches:\n",
    "        # Check if it's only in the raw CSV but not in the filtered df\n",
    "        exists_in_raw = raw_df[\"sku\"].astype(str).str.strip().eq(sku_str).any()\n",
    "        if exists_in_raw:\n",
    "            raise ValueError(\n",
    "                f\"SKU {sku_str!r} exists in san_leandro_products.csv but \"\n",
    "                \"does not have an embedding (likely missing image_filename \"\n",
    "                \"in the filtered set).\"\n",
    "            )\n",
    "        raise ValueError(f\"SKU {sku_str!r} not found in san_leandro_products.csv.\")\n",
    "    return matches[0]\n",
    "\n",
    "\n",
    "def find_index_by_name_substring(substr: str, occurrence: int = 0) -> int:\n",
    "    \"\"\"\n",
    "    Find the index of a product whose name contains the given substring\n",
    "    (case-insensitive). If multiple matches exist, `occurrence` chooses\n",
    "    which one (0 = first).\n",
    "    \"\"\"\n",
    "    mask = df[\"name\"].str.contains(substr, case=False, na=False)\n",
    "    matches = df[mask]\n",
    "    if matches.empty:\n",
    "        raise ValueError(f\"No products with name containing {substr!r}\")\n",
    "    if occurrence >= len(matches):\n",
    "        raise ValueError(\n",
    "            f\"Only {len(matches)} matches for {substr!r}, but occurrence={occurrence}\"\n",
    "        )\n",
    "    return matches.index[occurrence]\n",
    "\n",
    "\n",
    "def search_similar_by_index(query_idx: int, top_k: int = 10, exclude_same: bool = True):\n",
    "    \"\"\"\n",
    "    Given a row index in df, return the top_k most similar products by image\n",
    "    embedding, but RESTRICTED to the same material bucket.\n",
    "    \"\"\"\n",
    "    query_vec = image_embs[query_idx].reshape(1, -1)\n",
    "    # ask for extra neighbors in case many get filtered out by material bucket\n",
    "    distances, indices = nn.kneighbors(query_vec, n_neighbors=top_k + 30)\n",
    "\n",
    "    query_bucket = df.loc[query_idx, \"material_bucket\"]\n",
    "\n",
    "    dist_list = distances[0].tolist()\n",
    "    idx_list = indices[0].tolist()\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(dist_list, idx_list):\n",
    "        if exclude_same and idx == query_idx:\n",
    "            continue\n",
    "\n",
    "        row = df.iloc[idx]\n",
    "        if df.loc[idx, \"material_bucket\"] != query_bucket:\n",
    "            # different material/type -> skip\n",
    "            continue\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"index\": int(idx),\n",
    "                \"rank\": len(results) + 1,\n",
    "                \"sku\": row[\"sku\"],\n",
    "                \"name\": row[\"name\"],\n",
    "                \"category_slug\": row.get(\"category_slug\"),\n",
    "                \"material_bucket\": df.loc[idx, \"material_bucket\"],\n",
    "                \"distance\": float(dist),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_product_image(row, title_prefix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Display the product image for a given row of df.\n",
    "    \"\"\"\n",
    "    img_name = row.get(\"image_filename\")\n",
    "    if not isinstance(img_name, str) or not img_name:\n",
    "        print(\"No image_filename for this row.\")\n",
    "        return\n",
    "\n",
    "    img_path = IMAGES_DIR / img_name\n",
    "    if not img_path.exists():\n",
    "        print(\"Image file not found:\", img_path)\n",
    "        return\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    title = f\"{title_prefix}SKU {row['sku']} â€“ {row['name']}\"\n",
    "    plt.title(title, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_results_with_images(query_idx: int, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Convenience: show query product + top_k similar products with images.\n",
    "    \"\"\"\n",
    "    query_row = df.iloc[query_idx]\n",
    "    query_bucket = df.loc[query_idx, \"material_bucket\"]\n",
    "\n",
    "    print(\"QUERY PRODUCT\")\n",
    "    print(\"SKU:\", query_row[\"sku\"])\n",
    "    print(\"Name:\", query_row[\"name\"])\n",
    "    print(\"Category:\", query_row.get(\"category_slug\"))\n",
    "    print(\"Material bucket:\", query_bucket)\n",
    "    show_product_image(query_row, title_prefix=\"QUERY: \")\n",
    "\n",
    "    results = search_similar_by_index(query_idx, top_k=top_k)\n",
    "\n",
    "    print(\"\\nSIMILAR PRODUCTS\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    for r in results:\n",
    "        row = df.iloc[r[\"index\"]]\n",
    "        print(\n",
    "            f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f} \"\n",
    "            f\"| bucket={r['material_bucket']}\"\n",
    "        )\n",
    "        print(\"  Name:\", r[\"name\"])\n",
    "        print(\"  Category:\", r[\"category_slug\"])\n",
    "        show_product_image(row, title_prefix=f\"RANK {r['rank']}: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sku = \"101156321\"  # change this to a valid SKU from df[\"sku\"]\n",
    "\n",
    "query_idx = get_index_by_sku(query_sku)\n",
    "query_row = df.iloc[query_idx]\n",
    "\n",
    "print(\"QUERY PRODUCT\")\n",
    "print(\"SKU:\", query_row[\"sku\"])\n",
    "print(\"Name:\", query_row[\"name\"])\n",
    "print(\"Category:\", query_row.get(\"category_slug\"))\n",
    "print()\n",
    "\n",
    "results = search_similar_by_index(query_idx, top_k=5)\n",
    "\n",
    "print(\"SIMILAR PRODUCTS\")\n",
    "print(\"----------------\")\n",
    "for r in results:\n",
    "    print(f\"Rank {r['rank']} | SKU {r['sku']} | dist={r['distance']:.4f}\")\n",
    "    print(\"  Name:\", r[\"name\"])\n",
    "    print(\"  Category:\", r[\"category_slug\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sku = \"101156321\"  # change to a valid SKU from df[\"sku\"]\n",
    "\n",
    "query_idx = get_index_by_sku(query_sku)\n",
    "show_results_with_images(query_idx, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
